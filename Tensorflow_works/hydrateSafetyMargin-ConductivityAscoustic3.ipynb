{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "from numpy import hstack\n",
    "import matplotlib.pyplot as plt\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "import featuretools as ft\n",
    "import featuretools.variable_types as vtypes\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "# mlp for multi-output regression\n",
    "# from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedKFold, cross_val_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import(\n",
    "    classification_report, confusion_matrix, accuracy_score, mean_squared_error, mean_absolute_error\n",
    ")\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, LabelBinarizer, FunctionTransformer,PolynomialFeatures, OrdinalEncoder\n",
    ")\n",
    "# from sklearn_pandas import DataFrameMapper, CategoricalImputer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor,RegressorChain\n",
    "from sklearn.svm import LinearSVR\n",
    "# from sklearn.multioutput import RegressorChain\n",
    "from sklearn_pandas import DataFrameMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = pd.read_csv('D:\\\\desktop files\\\\weka\\\\Datasets\\\\Dr Wiabu\\\\AA-NACL.csv',header=0,\n",
    "                    names=['temp','conductivity','velocity','nacl','aa'],dtype='float32')\n",
    "df = pd.read_csv('D:\\\\desktop files\\\\weka\\\\Datasets\\\\Dr Wiabu\\\\aa-nacl-generated\\\\AA_NACL_NewFeatures_Corr.csv',dtype='float64')\n",
    "df_test = pd.read_csv('D:\\\\desktop files\\\\weka\\\\Datasets\\\\Dr Wiabu\\\\aa-nacl-generated\\\\AA_NACL_NewFeatures_Corr_test.csv',dtype='float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_shuffled = aa.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>conductivity</th>\n",
       "      <th>velocity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.0</td>\n",
       "      <td>29.139999</td>\n",
       "      <td>1465.199951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>25.0</td>\n",
       "      <td>17.930000</td>\n",
       "      <td>1511.699951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1421.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>15.0</td>\n",
       "      <td>14.480000</td>\n",
       "      <td>1480.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>15.0</td>\n",
       "      <td>38.939999</td>\n",
       "      <td>1501.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.330000</td>\n",
       "      <td>1415.900024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.720000</td>\n",
       "      <td>1418.599976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.420000</td>\n",
       "      <td>1420.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>25.0</td>\n",
       "      <td>17.940001</td>\n",
       "      <td>1508.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>15.0</td>\n",
       "      <td>14.310000</td>\n",
       "      <td>1485.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    temp  conductivity     velocity\n",
       "38   4.0     29.139999  1465.199951\n",
       "96  25.0     17.930000  1511.699951\n",
       "21   4.0      0.100000  1421.900024\n",
       "72  15.0     14.480000  1480.800049\n",
       "78  15.0     38.939999  1501.900024\n",
       "..   ...           ...          ...\n",
       "7    0.0      9.330000  1415.900024\n",
       "9    0.0      9.720000  1418.599976\n",
       "10   0.0      9.420000  1420.400024\n",
       "92  25.0     17.940001  1508.099976\n",
       "75  15.0     14.310000  1485.000000\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = aa_shuffled.drop(aa_shuffled.iloc[:,3:5],axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nacl</th>\n",
       "      <th>aa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nacl   aa\n",
       "38   3.0  1.5\n",
       "96   1.0  2.8\n",
       "21   0.0  0.2\n",
       "72   1.0  1.0\n",
       "78   3.0  0.5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = aa_shuffled.iloc[:,3:5]\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_org = X_train.copy()\n",
    "X_test_org = X_test.copy()\n",
    "y_train_org = y_train.copy()\n",
    "y_test_org = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = DataFrameMapper([\n",
    "    (['temp'],  [SimpleImputer(strategy='mean')]),\n",
    "#     (['temp'],  [SimpleImputer(strategy='mean'), OrdinalEncoder()]),\n",
    "    (['conductivity'],  [SimpleImputer(strategy='mean'), StandardScaler()]),\n",
    "    (['velocity'],  [SimpleImputer(strategy='mean'), StandardScaler()])\n",
    "], df_out=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This class performs feature engineering on the retrieved posts.  It is designed to be used in a pipeline\n",
    "It takes no special input parameters beyond X (the dataframe to be transformed) and returns a modified version of X\n",
    "with some additional, calculated columns.\n",
    "Columns Created:\n",
    "\n",
    "'''\n",
    "class TitanicTransformer(TransformerMixin):\n",
    "    def transform(self, X, **transform_params):\n",
    "        X['vel-con'] = X['conductivity']/np.median(X['velocity'])\n",
    "        return X\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1a = Pipeline([\n",
    "    ('map', mapper),\n",
    "    ('feature_gen', TitanicTransformer())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1a = pipe1a.fit(X_train)\n",
    "X_train = pipe1a.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test =  pipe1a.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Baseline Classification Accuracy Score on this dataframe before we add any new features\n",
    "\n",
    "#### Start with DecisionTreeClassifier \n",
    "* (parameters previously tuned using GridSearchCV on this dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =  pipe1a.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1. , 0.5],\n",
       "        [0. , 0.5],\n",
       "        [0. , 2. ],\n",
       "        [1. , 1.5],\n",
       "        [1. , 0.2],\n",
       "        [0. , 1.5],\n",
       "        [1. , 2.8],\n",
       "        [0. , 3. ],\n",
       "        [0. , 3. ],\n",
       "        [3. , 1.5],\n",
       "        [1. , 2. ],\n",
       "        [0. , 2.8],\n",
       "        [1. , 2.8],\n",
       "        [0. , 2. ],\n",
       "        [1. , 1. ],\n",
       "        [3. , 0.5],\n",
       "        [1. , 2.8],\n",
       "        [3. , 2. ],\n",
       "        [3. , 2.8],\n",
       "        [0. , 2. ],\n",
       "        [3. , 1. ]], dtype=float32)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[y_test.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  from sklearn.metrics import explained_variance_score\n",
    "# explained_variance_score(y_true, y_pred, multioutput='raw_values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_regression(X_train, y_train,X_test,y_test):\n",
    "    ESTIMATORS = {\n",
    "        \"K-nn\": KNeighborsRegressor(),                          # Accept default parameters\n",
    "        \"Linear regression\": LinearRegression(),\n",
    "        \"RandomForestRegressor\": RandomForestRegressor(max_depth=4, random_state=2),\n",
    "        \"Decision Tree Regressor\":DecisionTreeRegressor(max_depth=5),\n",
    "        \"RegressorChain Regressor\":RegressorChain(DecisionTreeRegressor()),\n",
    "        \"MultiOutputRegressor Regressor\":MultiOutputRegressor(LinearRegression()),\n",
    "        \"RegressorChain_Linear Regressor\":RegressorChain(LinearRegression()),\n",
    "        \"MultiOutput_DecisionTree Regressor\":MultiOutputRegressor(DecisionTreeRegressor())\n",
    "    }\n",
    "    # 9.1 Create an empty dictionary to collect prediction values\n",
    "    y_test_predict = dict()\n",
    "    y_mse = dict()\n",
    "    for name, estimator in ESTIMATORS.items():     \n",
    "        estimator.fit(X_train, y_train)                    # fit() with instantiated object\n",
    "        y_test_predict[name] = estimator.predict(X_test)   # Make predictions and save it in dict under key: name\n",
    "        y_mse[name] = mean_squared_error(y_test, estimator.predict(X_test))\n",
    "        print('Predicted: %s' % y_mse[name])\n",
    "    #     print('Predicted: %s' %  y_test_predict[name])\n",
    "    return y_test_predict.items()\n",
    "    \n",
    "    #     scoring = ['precision_macro', 'recall_macro']\n",
    "#     cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# #     n_scores = cross_validate(wrapper, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "#     n_scores = cross_val_score(wrapper, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "#     n_scores = np.absolute(n_scores)\n",
    "#     # summarize performance\n",
    "#     print('MAE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 0.6572763\n",
      "Predicted: 0.7080265\n",
      "Predicted: 0.3088927007769612\n",
      "Predicted: 0.5272136781468516\n",
      "Predicted: 0.590714274545511\n",
      "Predicted: 0.7080265\n",
      "Predicted: 0.708026484014447\n",
      "Predicted: 0.768095231893517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('K-nn', array([[1.       , 1.5      ],\n",
       "       [1.       , 1.9      ],\n",
       "       [0.       , 1.24     ],\n",
       "       [1.       , 1.86     ],\n",
       "       [1.       , 1.6      ],\n",
       "       [1.       , 1.4399999],\n",
       "       [1.       , 1.24     ],\n",
       "       [1.       , 1.4399999],\n",
       "       [0.8      , 1.96     ],\n",
       "       [3.       , 1.86     ],\n",
       "       [1.       , 1.24     ],\n",
       "       [0.       , 1.24     ],\n",
       "       [1.       , 1.6      ],\n",
       "       [0.       , 1.76     ],\n",
       "       [1.       , 1.6      ],\n",
       "       [3.       , 1.54     ],\n",
       "       [1.       , 1.04     ],\n",
       "       [3.       , 1.76     ],\n",
       "       [3.       , 1.54     ],\n",
       "       [0.8      , 1.96     ],\n",
       "       [3.       , 1.96     ]], dtype=float32)), ('Linear regression', array([[1.4793462 , 1.5352261 ],\n",
       "       [1.0115418 , 1.4175586 ],\n",
       "       [0.1071887 , 1.4378753 ],\n",
       "       [0.9348966 , 1.4609118 ],\n",
       "       [1.386753  , 1.566263  ],\n",
       "       [0.64869857, 0.94139993],\n",
       "       [1.1378682 , 1.664488  ],\n",
       "       [0.66461504, 1.0161879 ],\n",
       "       [0.89117   , 1.586407  ],\n",
       "       [2.303678  , 1.8711286 ],\n",
       "       [1.1370847 , 1.6324435 ],\n",
       "       [0.11374581, 1.4593792 ],\n",
       "       [1.375064  , 1.6824007 ],\n",
       "       [0.47450423, 1.5612383 ],\n",
       "       [1.4040318 , 1.6031348 ],\n",
       "       [2.3755124 , 1.7386897 ],\n",
       "       [1.0926173 , 1.1139066 ],\n",
       "       [1.8937321 , 1.3556645 ],\n",
       "       [2.3065836 , 1.805016  ],\n",
       "       [0.8827565 , 1.5357955 ],\n",
       "       [2.2920895 , 1.841151  ]], dtype=float32)), ('RandomForestRegressor', array([[0.99172294, 1.0393397 ],\n",
       "       [0.14411963, 1.52993061],\n",
       "       [0.28348702, 2.55193807],\n",
       "       [0.9985    , 1.92734601],\n",
       "       [0.99954545, 1.45384437],\n",
       "       [0.15347677, 1.81055238],\n",
       "       [0.99804545, 1.55654669],\n",
       "       [0.27965964, 2.53608251],\n",
       "       [0.28882631, 2.6051714 ],\n",
       "       [3.        , 2.2284755 ],\n",
       "       [0.99804545, 1.4159624 ],\n",
       "       [0.28348702, 2.55193807],\n",
       "       [0.99954545, 1.50099965],\n",
       "       [0.28332631, 2.57850235],\n",
       "       [0.99954545, 1.46140687],\n",
       "       [3.        , 1.4264032 ],\n",
       "       [0.89273062, 1.68485538],\n",
       "       [2.2185    , 1.86854102],\n",
       "       [3.        , 2.06909866],\n",
       "       [0.28882631, 2.57881029],\n",
       "       [2.98      , 1.48894097]])), ('Decision Tree Regressor', array([[1.        , 0.3       ],\n",
       "       [0.        , 0.5       ],\n",
       "       [0.2       , 2.76999998],\n",
       "       [1.        , 1.435     ],\n",
       "       [1.        , 1.435     ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 1.435     ],\n",
       "       [0.2       , 2.76999998],\n",
       "       [0.2       , 2.76999998],\n",
       "       [3.        , 3.        ],\n",
       "       [1.        , 1.435     ],\n",
       "       [0.2       , 2.76999998],\n",
       "       [1.        , 1.435     ],\n",
       "       [0.2       , 2.76999998],\n",
       "       [1.        , 1.435     ],\n",
       "       [3.        , 2.69999999],\n",
       "       [1.        , 1.435     ],\n",
       "       [3.        , 3.        ],\n",
       "       [3.        , 2.69999999],\n",
       "       [0.2       , 2.76999998],\n",
       "       [3.        , 3.        ]])), ('RegressorChain Regressor', array([[1.        , 0.5       ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.5       ],\n",
       "       [1.        , 2.        ],\n",
       "       [1.        , 0.5       ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 2.79999995],\n",
       "       [1.        , 2.79999995],\n",
       "       [3.        , 2.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 3.        ],\n",
       "       [1.        , 3.        ],\n",
       "       [1.        , 2.79999995],\n",
       "       [1.        , 0.5       ],\n",
       "       [3.        , 1.        ],\n",
       "       [1.        , 0.5       ],\n",
       "       [1.        , 2.        ],\n",
       "       [3.        , 2.79999995],\n",
       "       [1.        , 2.79999995],\n",
       "       [3.        , 1.        ]])), ('MultiOutputRegressor Regressor', array([[1.4793462 , 1.5352261 ],\n",
       "       [1.0115418 , 1.4175587 ],\n",
       "       [0.1071887 , 1.4378753 ],\n",
       "       [0.9348966 , 1.4609115 ],\n",
       "       [1.386753  , 1.566263  ],\n",
       "       [0.64869857, 0.94139993],\n",
       "       [1.1378682 , 1.6644878 ],\n",
       "       [0.66461504, 1.016188  ],\n",
       "       [0.89117   , 1.586407  ],\n",
       "       [2.303678  , 1.8711284 ],\n",
       "       [1.1370847 , 1.6324435 ],\n",
       "       [0.11374581, 1.4593792 ],\n",
       "       [1.375064  , 1.6824007 ],\n",
       "       [0.47450423, 1.5612383 ],\n",
       "       [1.4040319 , 1.6031348 ],\n",
       "       [2.3755124 , 1.7386895 ],\n",
       "       [1.0926173 , 1.1139069 ],\n",
       "       [1.8937321 , 1.3556645 ],\n",
       "       [2.3065836 , 1.8050159 ],\n",
       "       [0.8827565 , 1.5357955 ],\n",
       "       [2.2920895 , 1.841151  ]], dtype=float32)), ('RegressorChain_Linear Regressor', array([[1.47934613, 1.53522613],\n",
       "       [1.01154183, 1.41755868],\n",
       "       [0.10718874, 1.43787529],\n",
       "       [0.9348966 , 1.46091167],\n",
       "       [1.38675295, 1.56626303],\n",
       "       [0.64869861, 0.94139999],\n",
       "       [1.1378682 , 1.66448792],\n",
       "       [0.664615  , 1.01618799],\n",
       "       [0.89117001, 1.586407  ],\n",
       "       [2.30367801, 1.87112858],\n",
       "       [1.13708479, 1.63244356],\n",
       "       [0.11374587, 1.45937921],\n",
       "       [1.37506403, 1.68240072],\n",
       "       [0.4745043 , 1.56123831],\n",
       "       [1.40403184, 1.60313481],\n",
       "       [2.37551238, 1.7386897 ],\n",
       "       [1.09261727, 1.1139068 ],\n",
       "       [1.89373212, 1.35566446],\n",
       "       [2.30658364, 1.80501604],\n",
       "       [0.88275647, 1.53579548],\n",
       "       [2.29208949, 1.84115111]])), ('MultiOutput_DecisionTree Regressor', array([[1.        , 0.5       ],\n",
       "       [1.        , 1.5       ],\n",
       "       [1.        , 1.5       ],\n",
       "       [1.        , 2.        ],\n",
       "       [1.        , 0.5       ],\n",
       "       [1.        , 1.5       ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 2.79999995],\n",
       "       [1.        , 2.79999995],\n",
       "       [3.        , 3.        ],\n",
       "       [1.        , 1.        ],\n",
       "       [1.        , 3.        ],\n",
       "       [1.        , 3.        ],\n",
       "       [1.        , 2.79999995],\n",
       "       [1.        , 0.5       ],\n",
       "       [3.        , 3.        ],\n",
       "       [1.        , 2.79999995],\n",
       "       [1.        , 0.2       ],\n",
       "       [3.        , 2.79999995],\n",
       "       [1.        , 2.79999995],\n",
       "       [3.        , 2.        ]]))])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_regression(X_train, y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted K-nn: [[1.        1.5      ]\n",
      " [1.        1.9      ]\n",
      " [0.        1.24     ]\n",
      " [1.        1.86     ]\n",
      " [1.        1.6      ]\n",
      " [1.        1.4399999]\n",
      " [1.        1.24     ]\n",
      " [1.        1.4399999]\n",
      " [0.8       1.96     ]\n",
      " [3.        1.86     ]\n",
      " [1.        1.24     ]\n",
      " [0.        1.24     ]\n",
      " [1.        1.6      ]\n",
      " [0.        1.76     ]\n",
      " [1.        1.6      ]\n",
      " [3.        1.54     ]\n",
      " [1.        1.04     ]\n",
      " [3.        1.76     ]\n",
      " [3.        1.54     ]\n",
      " [0.8       1.96     ]\n",
      " [3.        1.96     ]]\n",
      "Predicted Linear: [[1.4793462  1.5352261 ]\n",
      " [1.0115418  1.4175586 ]\n",
      " [0.1071887  1.4378753 ]\n",
      " [0.9348966  1.4609118 ]\n",
      " [1.386753   1.566263  ]\n",
      " [0.64869857 0.94139993]\n",
      " [1.1378682  1.664488  ]\n",
      " [0.66461504 1.0161879 ]\n",
      " [0.89117    1.586407  ]\n",
      " [2.303678   1.8711286 ]\n",
      " [1.1370847  1.6324435 ]\n",
      " [0.11374581 1.4593792 ]\n",
      " [1.375064   1.6824007 ]\n",
      " [0.47450423 1.5612383 ]\n",
      " [1.4040318  1.6031348 ]\n",
      " [2.3755124  1.7386897 ]\n",
      " [1.0926173  1.1139066 ]\n",
      " [1.8937321  1.3556645 ]\n",
      " [2.3065836  1.805016  ]\n",
      " [0.8827565  1.5357955 ]\n",
      " [2.2920895  1.841151  ]]\n",
      "Predicted RandomForestRegressor: [[0.99172294 1.0393397 ]\n",
      " [0.14411963 1.52993061]\n",
      " [0.28348702 2.55193807]\n",
      " [0.9985     1.92734601]\n",
      " [0.99954545 1.45384437]\n",
      " [0.15347677 1.81055238]\n",
      " [0.99804545 1.55654669]\n",
      " [0.27965964 2.53608251]\n",
      " [0.28882631 2.6051714 ]\n",
      " [3.         2.2284755 ]\n",
      " [0.99804545 1.4159624 ]\n",
      " [0.28348702 2.55193807]\n",
      " [0.99954545 1.50099965]\n",
      " [0.28332631 2.57850235]\n",
      " [0.99954545 1.46140687]\n",
      " [3.         1.4264032 ]\n",
      " [0.89273062 1.68485538]\n",
      " [2.2185     1.86854102]\n",
      " [3.         2.06909866]\n",
      " [0.28882631 2.57881029]\n",
      " [2.98       1.48894097]]\n",
      "Predicted Decision Tree: [[1.         0.3       ]\n",
      " [0.         1.83333333]\n",
      " [0.2        2.76999998]\n",
      " [1.         1.435     ]\n",
      " [1.         1.435     ]\n",
      " [0.         1.83333333]\n",
      " [1.         1.435     ]\n",
      " [0.2        2.76999998]\n",
      " [0.2        2.76999998]\n",
      " [3.         3.        ]\n",
      " [1.         1.435     ]\n",
      " [0.2        2.76999998]\n",
      " [1.         1.435     ]\n",
      " [0.2        2.76999998]\n",
      " [1.         1.435     ]\n",
      " [3.         1.74999999]\n",
      " [1.         1.435     ]\n",
      " [1.         1.435     ]\n",
      " [3.         2.69999999]\n",
      " [0.2        2.76999998]\n",
      " [3.         3.        ]]\n",
      "Predicted RegressorChain: [[1.         0.5       ]\n",
      " [1.         0.5       ]\n",
      " [1.         3.        ]\n",
      " [1.         2.        ]\n",
      " [1.         0.5       ]\n",
      " [1.         1.5       ]\n",
      " [1.         1.        ]\n",
      " [1.         2.79999995]\n",
      " [1.         2.79999995]\n",
      " [3.         3.        ]\n",
      " [1.         1.        ]\n",
      " [1.         3.        ]\n",
      " [1.         3.        ]\n",
      " [1.         2.79999995]\n",
      " [1.         0.5       ]\n",
      " [3.         2.        ]\n",
      " [1.         0.5       ]\n",
      " [3.         2.        ]\n",
      " [3.         3.        ]\n",
      " [1.         2.79999995]\n",
      " [3.         2.        ]]\n",
      "Predicted MultiOutputRegressor: [[1.4793462  1.5352261 ]\n",
      " [1.0115418  1.4175587 ]\n",
      " [0.1071887  1.4378753 ]\n",
      " [0.9348966  1.4609115 ]\n",
      " [1.386753   1.566263  ]\n",
      " [0.64869857 0.94139993]\n",
      " [1.1378682  1.6644878 ]\n",
      " [0.66461504 1.016188  ]\n",
      " [0.89117    1.586407  ]\n",
      " [2.303678   1.8711284 ]\n",
      " [1.1370847  1.6324435 ]\n",
      " [0.11374581 1.4593792 ]\n",
      " [1.375064   1.6824007 ]\n",
      " [0.47450423 1.5612383 ]\n",
      " [1.4040319  1.6031348 ]\n",
      " [2.3755124  1.7386895 ]\n",
      " [1.0926173  1.1139069 ]\n",
      " [1.8937321  1.3556645 ]\n",
      " [2.3065836  1.8050159 ]\n",
      " [0.8827565  1.5357955 ]\n",
      " [2.2920895  1.841151  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None, None, None)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(print('Predicted K-nn: %s' % y_test_predict['K-nn']),\n",
    "print('Predicted Linear: %s' % y_test_predict[\"Linear regression\"]),\n",
    "print('Predicted RandomForestRegressor: %s' % y_test_predict[\"RandomForestRegressor\"]),\n",
    "print('Predicted Decision Tree: %s' % y_test_predict[\"Decision Tree Regressor\"]),\n",
    "print('Predicted RegressorChain: %s' % y_test_predict[\"RegressorChain Regressor\"]),\n",
    "print('Predicted MultiOutputRegressor: %s' % y_test_predict[\"MultiOutputRegressor Regressor\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running regression on the extracted dataset manually removed some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 14 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   Id                                   21 non-null     float64\n",
      " 1   temp                                 21 non-null     float64\n",
      " 2   conductivity = 0.6872724890708923    21 non-null     float64\n",
      " 3   conductivity = -0.45598065853118896  21 non-null     float64\n",
      " 4   conductivity = 1.5027929544448853    21 non-null     float64\n",
      " 5   conductivity = 0.654707133769989     21 non-null     float64\n",
      " 6   conductivity = 0.642235279083252     21 non-null     float64\n",
      " 7   conductivity = 0.6283775568008423    21 non-null     float64\n",
      " 8   conductivity = -0.42895829677581787  21 non-null     float64\n",
      " 9   conductivity = -0.45736637711524963  21 non-null     float64\n",
      " 10  conductivity = -1.0483936071395874   21 non-null     float64\n",
      " 11  conductivity = -1.0504722595214844   21 non-null     float64\n",
      " 12  vel-con                              21 non-null     float64\n",
      " 13  conductivity2.COUNT(concentration)   21 non-null     float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 2.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1.6618667\n",
      "Predicted: 1.1086955743145341\n",
      "Predicted: 1.3063790952987835\n",
      "Predicted: 1.3646447194308684\n",
      "Predicted: 2.7640476141089487\n",
      "Predicted: 1.1086955743145337\n",
      "Predicted: 1.1086955743145332\n",
      "Predicted: 2.8409523744384453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('K-nn', array([[1.8       , 1.5600001 ],\n",
       "       [1.8       , 2.52      ],\n",
       "       [1.8       , 1.1       ],\n",
       "       [1.8       , 1.1       ],\n",
       "       [2.4       , 2.06      ],\n",
       "       [2.4       , 0.93999994],\n",
       "       [1.8       , 1.14      ],\n",
       "       [2.4       , 2.42      ],\n",
       "       [1.8       , 1.6       ],\n",
       "       [1.4       , 0.93999994],\n",
       "       [1.8       , 1.24      ],\n",
       "       [0.6       , 1.96      ],\n",
       "       [1.2       , 2.1       ],\n",
       "       [1.        , 1.4       ],\n",
       "       [1.2       , 1.6       ],\n",
       "       [0.6       , 2.        ],\n",
       "       [1.2       , 1.5       ],\n",
       "       [1.8       , 1.4399999 ],\n",
       "       [1.        , 1.74      ],\n",
       "       [1.        , 1.74      ],\n",
       "       [1.        , 1.74      ]], dtype=float32)), ('Linear regression', array([[1.29736166, 1.55394936],\n",
       "       [1.1859945 , 1.63089948],\n",
       "       [1.5602305 , 1.46399683],\n",
       "       [1.34957079, 1.54675396],\n",
       "       [1.43495502, 1.52490248],\n",
       "       [1.44323193, 1.49771736],\n",
       "       [1.69583201, 1.41392309],\n",
       "       [1.25228927, 1.63565295],\n",
       "       [1.44598428, 1.51535741],\n",
       "       [1.31807263, 1.53453427],\n",
       "       [1.36797554, 1.53050026],\n",
       "       [1.26794247, 1.62378591],\n",
       "       [0.95127999, 1.69369256],\n",
       "       [1.45810927, 1.48223336],\n",
       "       [1.2362201 , 1.57062952],\n",
       "       [1.0719039 , 1.65214168],\n",
       "       [1.20614886, 1.56169985],\n",
       "       [1.73706165, 1.38220097],\n",
       "       [1.24196491, 1.56373812],\n",
       "       [1.39123436, 1.50980573],\n",
       "       [3.32479915, 0.99354663]])), ('RandomForestRegressor', array([[1.60295856, 1.34991917],\n",
       "       [1.60328737, 1.82204626],\n",
       "       [1.75788285, 1.25201729],\n",
       "       [1.71747488, 1.61300946],\n",
       "       [1.69397048, 1.47931739],\n",
       "       [1.76727079, 1.42746038],\n",
       "       [1.64388053, 1.22920189],\n",
       "       [1.30649668, 1.78728049],\n",
       "       [1.62379365, 1.38611154],\n",
       "       [1.30220655, 1.45139634],\n",
       "       [1.33424781, 1.54264158],\n",
       "       [1.17744724, 1.74170665],\n",
       "       [1.32559919, 1.70226314],\n",
       "       [1.20939946, 1.52812752],\n",
       "       [1.319897  , 1.56862041],\n",
       "       [1.27231419, 1.85437677],\n",
       "       [1.13712742, 1.47446927],\n",
       "       [1.25126811, 1.42912118],\n",
       "       [1.29954427, 1.57612577],\n",
       "       [1.31527008, 1.56780319],\n",
       "       [1.35072425, 1.77417366]])), ('Decision Tree Regressor', array([[1.5862069 , 1.27586206],\n",
       "       [0.72727273, 2.39090909],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [0.72727273, 2.39090909],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [0.72727273, 2.39090909],\n",
       "       [0.72727273, 2.39090909],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [0.72727273, 2.39090909],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [1.5862069 , 1.27586206],\n",
       "       [0.72727273, 2.39090909]])), ('RegressorChain Regressor', array([[0. , 2. ],\n",
       "       [0. , 0.5],\n",
       "       [3. , 2. ],\n",
       "       [3. , 3. ],\n",
       "       [3. , 0.2],\n",
       "       [3. , 2. ],\n",
       "       [3. , 2. ],\n",
       "       [1. , 3. ],\n",
       "       [3. , 0.2],\n",
       "       [1. , 2. ],\n",
       "       [3. , 3. ],\n",
       "       [1. , 3. ],\n",
       "       [3. , 3. ],\n",
       "       [1. , 2. ],\n",
       "       [3. , 2. ],\n",
       "       [1. , 3. ],\n",
       "       [3. , 2. ],\n",
       "       [0. , 2. ],\n",
       "       [3. , 2. ],\n",
       "       [3. , 2. ],\n",
       "       [1. , 3. ]])), ('MultiOutputRegressor Regressor', array([[1.29736166, 1.55394936],\n",
       "       [1.1859945 , 1.63089948],\n",
       "       [1.5602305 , 1.46399683],\n",
       "       [1.34957079, 1.54675396],\n",
       "       [1.43495502, 1.52490248],\n",
       "       [1.44323193, 1.49771736],\n",
       "       [1.69583201, 1.41392309],\n",
       "       [1.25228927, 1.63565295],\n",
       "       [1.44598428, 1.51535741],\n",
       "       [1.31807263, 1.53453427],\n",
       "       [1.36797554, 1.53050026],\n",
       "       [1.26794247, 1.62378591],\n",
       "       [0.95127999, 1.69369256],\n",
       "       [1.45810927, 1.48223336],\n",
       "       [1.2362201 , 1.57062952],\n",
       "       [1.0719039 , 1.65214168],\n",
       "       [1.20614886, 1.56169985],\n",
       "       [1.73706165, 1.38220097],\n",
       "       [1.24196491, 1.56373812],\n",
       "       [1.39123436, 1.50980573],\n",
       "       [3.32479915, 0.99354663]])), ('RegressorChain_Linear Regressor', array([[1.29736166, 1.55394936],\n",
       "       [1.1859945 , 1.63089948],\n",
       "       [1.5602305 , 1.46399683],\n",
       "       [1.34957079, 1.54675396],\n",
       "       [1.43495502, 1.52490248],\n",
       "       [1.44323193, 1.49771736],\n",
       "       [1.69583201, 1.41392309],\n",
       "       [1.25228927, 1.63565295],\n",
       "       [1.44598428, 1.51535741],\n",
       "       [1.31807263, 1.53453427],\n",
       "       [1.36797554, 1.53050026],\n",
       "       [1.26794247, 1.62378591],\n",
       "       [0.95127999, 1.69369256],\n",
       "       [1.45810927, 1.48223336],\n",
       "       [1.2362201 , 1.57062952],\n",
       "       [1.0719039 , 1.65214168],\n",
       "       [1.20614886, 1.56169985],\n",
       "       [1.73706165, 1.38220097],\n",
       "       [1.24196491, 1.56373812],\n",
       "       [1.39123436, 1.50980573],\n",
       "       [3.32479915, 0.99354663]])), ('MultiOutput_DecisionTree Regressor', array([[0. , 0.5],\n",
       "       [0. , 0.5],\n",
       "       [3. , 1. ],\n",
       "       [3. , 0.5],\n",
       "       [3. , 0.2],\n",
       "       [3. , 0.5],\n",
       "       [3. , 3. ],\n",
       "       [0. , 1.5],\n",
       "       [3. , 0.2],\n",
       "       [1. , 0.2],\n",
       "       [3. , 0.2],\n",
       "       [0. , 1.5],\n",
       "       [3. , 3. ],\n",
       "       [1. , 2. ],\n",
       "       [3. , 2. ],\n",
       "       [1. , 3. ],\n",
       "       [3. , 2. ],\n",
       "       [0. , 2. ],\n",
       "       [3. , 2. ],\n",
       "       [3. , 2. ],\n",
       "       [1. , 3. ]]))])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_regression(df, y_train,df_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aray = X_train.to_numpy()\n",
    "X_train_aray.shape\n",
    "\n",
    "X_test_aray = X_test.to_numpy()\n",
    "X_test_aray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_reg_makePred(X_train_aray, y_train,X_test_aray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURETOOLS FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = ft.EntitySet(id = 'hydrate')\n",
    "es.entity_from_dataframe(entity_id = 'concentration', dataframe = X_train, index = 'Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es[\"concentration\"].variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = es.normalize_entity(base_entity_id='concentration', new_entity_id='conductivity2', index='conductivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  tell DFS to ignore the PassengerId column( we don't want to generate any features for it) using the command ignore_variables={'Passengers':['PassengerId']}),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix, feature_names = ft.dfs(entityset=es, \n",
    "    target_entity = 'concentration', \n",
    "    max_depth = 2, \n",
    "    verbose = 3, \n",
    "    n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train=feature_matrix.copy() # save the generated features back into our X_Train\n",
    "feature_matrix.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repeat the steps for Encoding our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_enc, features_enc = ft.encode_features(feature_matrix, feature_names, include_unknown=False)\n",
    "feature_matrix_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train = feature_matrix_enc.copy()\n",
    "Xf_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a new entity set for test and repeat the steps for adding the Passengers and PClass entitiesÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating and entity set 'es'\n",
    "es_tst = ft.EntitySet(id = 'hydrate')\n",
    "# adding a dataframe \n",
    "es_tst.entity_from_dataframe(entity_id = 'concentration', dataframe = X_test, index = 'Id')\n",
    "# add PCLass entity\n",
    "es_tst = es_tst.normalize_entity(base_entity_id='concentration', new_entity_id='conductivity2', index='conductivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now call calculate_feature_matrix on our test entity set and pass in the list of saved features from trainingÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_tst = ft.calculate_feature_matrix(features=features_enc, entityset=es_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_test = feature_matrix_tst.copy()\n",
    "Xf_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_test.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for nulls\n",
    "for col in Xf_train.columns:\n",
    "    if Xf_train[col].isnull().sum() >0:\n",
    "        print(col)\n",
    "        Xf_train.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for nulls\n",
    "for col in Xf_test.columns:\n",
    "    if Xf_test[col].isnull().sum() >0:\n",
    "        print(col)\n",
    "        Xf_test.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now remove highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold for removing correlated variables\n",
    "threshold = 0.7\n",
    "\n",
    "# Absolute value correlation matrix\n",
    "corr_matrix = Xf_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "# Select columns with correlations above threshold\n",
    "collinear_features = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "print('There are %d features to remove.' % (len(collinear_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xf_train_flt = Xf_train.drop(columns = collinear_features)\n",
    "Xf_test_flt = Xf_test.drop(columns = collinear_features)\n",
    "Xf_train_flt.shape, Xf_test_flt.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
