{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ae3b0d-7d59-461b-a53f-b8df06b5b668",
   "metadata": {},
   "source": [
    "# Predicting with model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30706d4-3529-4ed4-8747-99c81b580fbc",
   "metadata": {},
   "source": [
    "## Text transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f8e440f-399f-4703-abeb-812fff2670b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "# import os\n",
    "# import json\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# import tensorflow_datasets as tfds\n",
    "import tensorflow_text as text  # A dependency of the preprocessing model\n",
    "import tensorflow_addons as tfa\n",
    "# from official.nlp import optimization\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    " # Import necessary libraries\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "import warnings\n",
    "import nltk, time\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "# Import Dictionary\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import collections, itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a1dd1f2-b255-4553-9cb0-3b535ed24f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.preprocessing import (LabelBinarizer, OrdinalEncoder,LabelEncoder,MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2e2f7dc5-f3b8-4201-88d2-a9e29ab6e81d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>crime_types</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Solomon Sauls ran an illegal enterprise wi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SummaryHarmony Gold Mine (Pty) Limited is a mi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SummaryThe three defendants were found guilty ...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Johannes Erasmus van Staden was a Cape Town bu...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Juan Hattingh was a young practicing attorney ...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    crime_types  sentence\n",
       "0  Mr. Solomon Sauls ran an illegal enterprise wi...  money laundry         1\n",
       "1  SummaryHarmony Gold Mine (Pty) Limited is a mi...  money laundry         1\n",
       "2  SummaryThe three defendants were found guilty ...  money laundry         1\n",
       "3  Johannes Erasmus van Staden was a Cape Town bu...  money laundry         1\n",
       "4  Juan Hattingh was a young practicing attorney ...  money laundry         1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../../../datasets/sherloc/sherloc_court_cases_7.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f421425-b3ba-41cb-aabb-c6de1f1c2620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to tokenize the tweets\n",
    "def custom_tokenize(text):\n",
    "    \"\"\"Function that tokenizes text\"\"\"\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    if not text:\n",
    "        print('The text to be tokenized is a None type. Defaulting to blank string.')\n",
    "        text = ''\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2f08827-7be4-47d9-9c3f-c110bdb48b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_up(data):\n",
    "    \"\"\"Function that cleans up the data into a shape that can be further used for modeling\"\"\"\n",
    "    # english = data[data['lang']=='en'] # extract only tweets in english language\n",
    "    data.drop_duplicates() # drop duplicate tweets\n",
    "    data['text'].dropna(inplace=True) # drop any rows with missing tweets\n",
    "    tokenized = data['text'].apply(custom_tokenize) # Tokenize tweets\n",
    "    lower_tokens = tokenized.apply(lambda x: [t.lower() for t in x]) # Convert tokens into lower case\n",
    "    alpha_only = lower_tokens.apply(lambda x: [t for t in x if t.isalpha()]) # Remove punctuations\n",
    "    no_stops = alpha_only.apply(lambda x: [t for t in x if t not in stopwords.words('english')]) # remove stop words\n",
    "    # no_stops.apply(lambda x: [x.remove(t) for t in x if t=='rt']) # remove acronym \"rt\"\n",
    "    return no_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "630ac9f9-0719-4ca1-a5e6-aea5e4e85275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_text_chunk = clean_up(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e32270-bdec-45ff-b867-6d795a3dd533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(cleaned_text_chunk.shape)\n",
    "print(cleaned_text_chunk.str.len().max())\n",
    "print(cleaned_text_chunk.str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c75627b-d43e-4cce-ae1c-2401be4583e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Dictionary from the tweets\n",
    "dictionary = Dictionary(cleaned_text_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91506c05-b7df-4a3e-9f41-c0731101a570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create corpus for bag of words (token IDs of each word with their frequencies)\n",
    "corpus = cleaned_text_chunk.apply(lambda x: dictionary.doc2bow(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27d81085-7a41-4089-88f9-18c81bde5804",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(0, 8), (1, 4), (2, 1), (3, 1), (4, 1), (5, 1...\n",
       "1       [(3, 2), (6, 2), (12, 1), (15, 1), (32, 3), (3...\n",
       "2       [(0, 6), (1, 1), (2, 1), (3, 1), (7, 4), (23, ...\n",
       "3       [(1, 1), (12, 2), (15, 2), (23, 1), (29, 2), (...\n",
       "4       [(15, 2), (23, 1), (31, 1), (44, 2), (51, 3), ...\n",
       "                              ...                        \n",
       "1245    [(1, 3), (26, 2), (43, 1), (58, 1), (70, 1), (...\n",
       "1246    [(235, 1), (346, 1), (791, 1), (1521, 1), (176...\n",
       "1247    [(1, 1), (26, 1), (48, 1), (58, 1), (70, 1), (...\n",
       "1248    [(58, 1), (124, 1), (143, 1), (195, 1), (252, ...\n",
       "1249    [(1, 1), (26, 3), (27, 1), (37, 3), (43, 2), (...\n",
       "Name: text, Length: 1250, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c688d038-2863-42a4-b95d-71971aec0faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>crime_types</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Solomon Sauls ran an illegal enterprise wi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SummaryHarmony Gold Mine (Pty) Limited is a mi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text    crime_types  sentence\n",
       "0  Mr. Solomon Sauls ran an illegal enterprise wi...  money laundry         1\n",
       "1  SummaryHarmony Gold Mine (Pty) Limited is a mi...  money laundry         1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rename(columns={'text':'raw_text'}, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28dce081-bb12-4426-b3a4-5adc9bc76757",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>crime_types</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Solomon Sauls ran an illegal enterprise wi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[solomon, sauls, ran, illegal, enterprise, pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SummaryHarmony Gold Mine (Pty) Limited is a mi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[summaryharmony, gold, mine, pty, limited, min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text    crime_types  sentence   \n",
       "0  Mr. Solomon Sauls ran an illegal enterprise wi...  money laundry         1  \\\n",
       "1  SummaryHarmony Gold Mine (Pty) Limited is a mi...  money laundry         1   \n",
       "\n",
       "                                                text  \n",
       "0  [solomon, sauls, ran, illegal, enterprise, pur...  \n",
       "1  [summaryharmony, gold, mine, pty, limited, min...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([data,cleaned_text_chunk],axis=1)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3411352-17ea-4a49-8565-75402973674a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>crime_types</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Solomon Sauls ran an illegal enterprise wi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[solomon, sauls, ran, illegal, enterprise, pur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SummaryHarmony Gold Mine (Pty) Limited is a mi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[summaryharmony, gold, mine, pty, limited, min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text    crime_types  sentence   \n",
       "0  Mr. Solomon Sauls ran an illegal enterprise wi...  money laundry         1  \\\n",
       "1  SummaryHarmony Gold Mine (Pty) Limited is a mi...  money laundry         1   \n",
       "\n",
       "                              tokenized_cleaned_text  \n",
       "0  [solomon, sauls, ran, illegal, enterprise, pur...  \n",
       "1  [summaryharmony, gold, mine, pty, limited, min...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename(columns={'text':'tokenized_cleaned_text'}, inplace=True)\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03f7a23d-d61c-4be4-b059-ef8e6b3316e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f6888f6-e337-4464-ba69-7dd7c0384ab5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.560123682022095"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatize tokens\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized'] = df['tokenized_cleaned_text'].apply(lambda x: [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b25dedbc-9d34-4c87-9032-c77a64b5610b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>crime_types</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_cleaned_text</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Solomon Sauls ran an illegal enterprise wi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[solomon, sauls, ran, illegal, enterprise, pur...</td>\n",
       "      <td>[solomon, saul, ran, illegal, enterprise, purp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SummaryHarmony Gold Mine (Pty) Limited is a mi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[summaryharmony, gold, mine, pty, limited, min...</td>\n",
       "      <td>[summaryharmony, gold, mine, pty, limited, min...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text    crime_types  sentence   \n",
       "0  Mr. Solomon Sauls ran an illegal enterprise wi...  money laundry         1  \\\n",
       "1  SummaryHarmony Gold Mine (Pty) Limited is a mi...  money laundry         1   \n",
       "\n",
       "                              tokenized_cleaned_text   \n",
       "0  [solomon, sauls, ran, illegal, enterprise, pur...  \\\n",
       "1  [summaryharmony, gold, mine, pty, limited, min...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [solomon, saul, ran, illegal, enterprise, purp...  \n",
       "1  [summaryharmony, gold, mine, pty, limited, min...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c56deae-a93d-4486-b51b-05771116b2c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>crime_types</th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokenized_cleaned_text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>tokens_back_to_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mr. Solomon Sauls ran an illegal enterprise wi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[solomon, sauls, ran, illegal, enterprise, pur...</td>\n",
       "      <td>[solomon, saul, ran, illegal, enterprise, purp...</td>\n",
       "      <td>solomon saul ran illegal enterprise purpose po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SummaryHarmony Gold Mine (Pty) Limited is a mi...</td>\n",
       "      <td>money laundry</td>\n",
       "      <td>1</td>\n",
       "      <td>[summaryharmony, gold, mine, pty, limited, min...</td>\n",
       "      <td>[summaryharmony, gold, mine, pty, limited, min...</td>\n",
       "      <td>summaryharmony gold mine pty limited mining co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text    crime_types  sentence   \n",
       "0  Mr. Solomon Sauls ran an illegal enterprise wi...  money laundry         1  \\\n",
       "1  SummaryHarmony Gold Mine (Pty) Limited is a mi...  money laundry         1   \n",
       "\n",
       "                              tokenized_cleaned_text   \n",
       "0  [solomon, sauls, ran, illegal, enterprise, pur...  \\\n",
       "1  [summaryharmony, gold, mine, pty, limited, min...   \n",
       "\n",
       "                                          lemmatized   \n",
       "0  [solomon, saul, ran, illegal, enterprise, purp...  \\\n",
       "1  [summaryharmony, gold, mine, pty, limited, min...   \n",
       "\n",
       "                                 tokens_back_to_text  \n",
       "0  solomon saul ran illegal enterprise purpose po...  \n",
       "1  summaryharmony gold mine pty limited mining co...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatized text back to tokenized\n",
    "# m= ast.literal_eval(f) # convert string to list just like json.loads()\n",
    "# df['tokens_back_to_text'] = [' '.join(map(str, ast.literal_eval(l))) for l in df['lemmatized']]\n",
    "df['tokens_back_to_text'] = [' '.join(map(str, l)) for l in df['lemmatized']]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a54543-54f8-42fb-8c0d-d9c3d2986e87",
   "metadata": {},
   "source": [
    "## model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e58c587-4d69-4f37-91dc-8d4eac9b80e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# class for Y convertions\n",
    "class TextLabelEncoderDummy:\n",
    "\n",
    "    def labelencoder(y_df):\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(y_df)\n",
    "        encoded_Y = encoder.transform(y_df)\n",
    "        return encoded_Y, encoder\n",
    "\n",
    "\n",
    "    def encoded_to_dummy(encoded_Y):\n",
    "        # convert encoder variable to dummy variable\n",
    "        uniques, ids = np.unique(encoded_Y, return_inverse=True)\n",
    "        dummy_y = to_categorical(ids, len(uniques))\n",
    "        # dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "        return dummy_y, uniques\n",
    "\n",
    "\n",
    "    def reverse_dummy_to_encoded(y_test):\n",
    "        reverse_dummy = uniques[y_test.argmax(1)]\n",
    "        return reverse_dummy\n",
    "\n",
    "\n",
    "    def reverse_encoded_to_text(reverse_dummy):\n",
    "        reverse_encoded = encoder.inverse_transform(reverse_dummy)\n",
    "        return reverse_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86bb66e-8278-4ac3-880a-037684e0a023",
   "metadata": {
    "tags": []
   },
   "source": [
    "### categorized y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "66892d54-d61e-408d-ab5b-ad6c6bc9da15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y = df.sentence.values\n",
    "y = [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f23bdfa6-0837-49b0-8c69-f6cb063de568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-hot encoding of labels\n",
    "encoded_Y, encoder = TextLabelEncoderDummy.labelencoder(y)\n",
    "dummy_y, uniques = TextLabelEncoderDummy.encoded_to_dummy(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7cc81666-bc3f-4dcf-b3c7-072ee746ac1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0]),\n",
       " array([0, 1]),\n",
       " array([[0., 1.],\n",
       "        [1., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y, uniques, dummy_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8fbe47e6-545c-4640-8412-43ca886451d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X = df.tokens_back_to_text.values[0]\n",
    "X = ['''solomon saul ran illegal enterprise purpose poach sell abalone haliotis midae south africa group\\ \n",
    "abalone diver work supply illegally harvest abalone accuse bribed official department agriculture forestry \\\n",
    "fishery prevent confiscate abalone buy back abalone already seize authority corrupt official face charge separate \\\n",
    "march police search accuse house encounter cash accuse confess proceeds illegal activity february defendant plead guilty \\\n",
    "count involve run illegal enterprise corruption money laundering possess transport illegally harvest aggravate sentence \\\n",
    "seriousness corrupt government official engagement illegal abalone trade commercial scale financial accuse involve similar \\\n",
    "crime past previously receive prison sentence involvement another illegal enterprise focus abalone found responsible run illegal \\\n",
    "abalone business different area hand current trial solomon saul sentence year imprisonment run concurrently result effective sentence \\\n",
    "year determine run concurrently previous sentence year''']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9227ca77-b5c9-4134-96f5-9977173149ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "26405b27-24a9-4645-bf84-7d6eb2d6e32f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solomon saul ran illegal enterprise purpose poach sell abalone haliotis midae south africa group\\\\ \\nabalone diver work supply illegally harvest abalone accuse bribed official department agriculture forestry fishery prevent confiscate abalone buy back abalone already seize authority corrupt official face charge separate march police search accuse house encounter cash accuse confess proceeds illegal activity february defendant plead guilty count involve run illegal enterprise corruption money laundering possess transport illegally harvest aggravate sentence seriousness corrupt government official engagement illegal abalone trade commercial scale financial accuse involve similar crime past previously receive prison sentence involvement another illegal enterprise focus abalone found responsible run illegal abalone business different area hand current trial solomon saul sentence year imprisonment run concurrently result effective sentence year determine run concurrently previous sentence year']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c55fb305-a26c-4322-ab05-e377d3fe0225",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36e16539-7a91-449e-8abc-3b3225ba0512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# integer encode the documents\n",
    "sequences = tokenizer.texts_to_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4cd92e9d-a368-47f2-a0f6-58b0a7179ffb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pad documents to a max length of 14 words\n",
    "maxlen = 25\n",
    "X = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2f7c8da-fc95-43f5-b281-7cdadd5fd117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 25)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08c9f1a1-4339-4a68-83ba-55edd29f9c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 6],\n",
       "       [0, 0, 0, ..., 0, 0, 8],\n",
       "       [0, 0, 0, ..., 0, 0, 5],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 2],\n",
       "       [0, 0, 0, ..., 0, 0, 3]], dtype=int32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ec0692e1-3e5b-45f7-a6de-d87271e47ebf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 10:11:55.083303: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 10:11:55.084939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 10:11:55.086165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 10:11:55.278216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 10:11:55.279518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 10:11:55.280799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 10:11:55.477647: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 10:11:55.479646: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 10:11:55.481230: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "lstm = load_model('lstm.h5')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d494d87-4c70-4b16-9173-8d658ec1f805",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 25, 32)            360352    \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 25, 20)            4240      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 25, 20)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 25, 10)            1240      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 25, 10)            0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 5)                 320       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 366,164\n",
      "Trainable params: 366,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4d7a2a77-7a13-4676-9641-a842a331d71c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# list(itertools.chain.from_iterable(X_test))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m Counter(\u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(\u001b[43my_test\u001b[49m)))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "# list(itertools.chain.from_iterable(X_test))\n",
    "Counter(list(itertools.chain.from_iterable(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11ae8f42-fd17-473d-89c0-a080285b713f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 11:08:19.793180: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 11:08:19.794912: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 11:08:19.796134: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 11:08:19.984329: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 11:08:19.985618: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 11:08:19.987203: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-05-10 11:08:20.173683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-05-10 11:08:20.175071: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-05-10 11:08:20.176256: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 1s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = lstm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65356304-51f7-41db-a52a-44bb1d96356a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_dummy_predicted =TextLabelEncoderDummy.reverse_dummy_to_encoded(predictions)\n",
    "print(pd.unique(reverse_dummy_predicted).shape)\n",
    "\n",
    "# There will be no need for this\n",
    "# reverse_encoded_y_predicted = TextLabelEncoderDummy.reverse_encoded_to_text(reverse_dummy_predicted)\n",
    "# reverse_encoded_y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e768446c-89e0-4cad-91e6-b7a0c0ebaa59",
   "metadata": {},
   "source": [
    "### ----End-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0cdefcd3-ad3b-4cec-aad9-7ec877fd14b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 999})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(reverse_encoded_y_predicted)\n",
    "Counter(list(itertools.chain(reverse_encoded_y_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d4ae1097-1350-4c29-867e-93984c93e072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7960f6e-63b0-44e3-a51b-3b3c01afdab7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7573bb9-d9f6-4574-af24-25a4e2a9299a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
